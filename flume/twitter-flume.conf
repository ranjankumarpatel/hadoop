#### TwitterAgent for collecting Twitter data to Hadoop HDFS #####

TwitterAgent.sources = Twitter
TwitterAgent.channels = FileChannel
TwitterAgent.sinks = HDFS
 
#TwitterAgent.sources.Twitter.type = com.cloudera.flume.source.TwitterSource
TwitterAgent.sources.Twitter.type = org.apache.flume.source.twitter.TwitterSource
TwitterAgent.sources.Twitter.channels = FileChannel
TwitterAgent.sources.Twitter.consumerKey = pvOELjGc67ip7ROLpGvFtGRiw
TwitterAgent.sources.Twitter.consumerSecret = V1ugdT3ogz4kf8miD4ak6sEKOZw01hHYvijCyddmbvbMgD3K0h
TwitterAgent.sources.Twitter.accessToken = 2744360029-aoanSDmn0iEvIL7rhboyXcbo4dlfxGf5JTCtj3V
TwitterAgent.sources.Twitter.accessTokenSecret = QdM6buOVbgClIxmtonsDmK9Hqf7QhNpxcsMx9TLRAWALl
TwitterAgent.sources.Twitter.keywords = tutorials point,java, bigdata, mapreduce, mahout, hbase, nosql
TwitterAgent.sources.Twitter.maxBatchSize = 50000
TwitterAgent.sources.Twitter.maxBatchDurationMillis = 100000
 
#TwitterAgent.sources.Twitter.keywords = Apache, Hadoop, Mapreduce, hadooptutorial, Hive, Hbase, MySql
 
TwitterAgent.sinks.HDFS.channel = FileChannel
TwitterAgent.sinks.HDFS.type = hdfs
TwitterAgent.sinks.HDFS.hdfs.path = hdfs://192.168.0.60:8020/user/cloudera/flume/tweets
TwitterAgent.sinks.HDFS.hdfs.fileType = DataStream
TwitterAgent.sinks.HDFS.hdfs.writeFormat = Text
TwitterAgent.sinks.HDFS.hdfs.batchSize = 200000
TwitterAgent.sinks.HDFS.hdfs.rollSize = 0
TwitterAgent.sinks.HDFS.hdfs.rollCount = 2000000
 
TwitterAgent.channels.FileChannel.type = file
TwitterAgent.channels.FileChannel.checkpointDir = /home/cloudera/log/flume/checkpoint/
TwitterAgent.channels.FileChannel.dataDirs = /home/cloudera/log/flume/data/